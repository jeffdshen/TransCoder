# TransCoder

## Pointers to modifications

Preprocessing:
1. Dataset utils: https://github.com/jeffdshen/TransCoder/blob/master/preprocessing/src/dataset_utils.py
2. Bytecode compilation: https://github.com/jeffdshen/TransCoder/blob/master/preprocessing/src/python_compiler.py
3. Bytecode tokenizer: https://github.com/jeffdshen/TransCoder/blob/master/preprocessing/src/dis_tokenizer.py
4. Parallel dataset: https://github.com/jeffdshen/TransCoder/blob/master/preprocessing/src/dataset.py#L31-L197

Model:
1. Predict any layer and loss: https://github.com/jeffdshen/TransCoder/blob/master/XLM/src/model/transformer.py#L194-L215
2. Predict any target vectors: https://github.com/jeffdshen/TransCoder/blob/master/XLM/src/model/transformer.py#L132-L149
3. Permute input sequence: https://github.com/jeffdshen/TransCoder/blob/master/XLM/src/trainer.py#L381-L392

Evaluation:
1. Assemble bytecode into code object: https://github.com/jeffdshen/TransCoder/blob/master/XLM/src/dis_assembler.py
2. Run bytecode unit tests: https://github.com/jeffdshen/TransCoder/blob/master/XLM/dis_script.py
3. Autogenerated scripts for bytecode: https://github.com/jeffdshen/TransCoder/tree/master/data/evaluation/geeks_for_geeks_successful_test_scripts/dis

Logs:
1. Evaluation logs and results: https://github.com/jeffdshen/TransCoder/tree/master/logs/eval
2. Misc logs (incomplete): https://github.com/jeffdshen/TransCoder/tree/master/logs

# Attribution

This repository modifies TransCoder in [Unsupervised Translation of Programming Languages](https://arxiv.org/pdf/2006.03511.pdf) by M.A. Lachaux*, B. Roziere*, L. Chanussot, G. Lample, used under a Creative Commons Attribution-NonCommercial 4.0 International license (See LICENSE for more details).
